# Releases and deploys commits, auto-merges PRs, and uploads test coverage info,
# etc using a privileged runner. To function, this workflow requires the working
# tree (including coverage info) and metadata artifacts at the following keys:
#   - `build-${{ runner.os }}-${{ github.sha }}`
#   - `metadata-${{ runner.os }}-${{ github.sha }}`
#
# * Note: feel free to run this workflow in forks (e.g. for testing your PR)
# * without worrying about this workflow attempting to deploy a package ðŸš€
#
# ! See also: https://securitylab.github.com/research/github-actions-preventing-pwn-requests/
# ! tl;dr: do not build anything or run any code or executables from the repo.
# ! Also for this reason, installing dependencies cannot happen either. Deps are
# ! hardcoded (called via `npx -p`) below, rather than taken from `package.json`
#
# ! To function, the following GitHub repository secrets must be defined:
# !   CODECOV_TOKEN (optional for public repos)
# !   GPG_PRIVATE_KEY
# !   GPG_PASSPHRASE
# !   GH_TOKEN
# !   NPM_TOKEN

name: deploy

on:
  workflow_run: # ! Privileged trusted code w/ full access tokens and secrets !
    types: [completed]
    branches: [main, canary]

jobs:
  metadata:
    name: 'gather-metadata'
    runs-on: ubuntu-latest
    timeout-minutes: 10

    outputs:
      should-skip:
        ${{ github.event.workflow_run.conclusion != 'success' ||
        steps.metadata.outputs.should-skip == 'true' }},
      node-version: ${{ steps.metadata.outputs.node-version }},
      current-branch: ${{ steps.metadata.outputs.current-branch }},
      commit-sha: ${{ steps.metadata.outputs.commit-sha }},
      pr-number: ${{ steps.metadata.outputs.pr-number }},
      can-release: ${{ steps.metadata.outputs.can-release }},
      can-automerge: ${{ steps.metadata.outputs.can-automerge }},
      can-retry-automerge: ${{ steps.metadata.outputs.can-retry-automerge }},
      can-upload-coverage: ${{ steps.metadata.outputs.can-upload-coverage }},
      has-deploy: ${{ steps.metadata.outputs.has-deploy }},
      has-release-config: ${{ steps.metadata.outputs.has-release-config }},
      has-docs: ${{ steps.metadata.outputs.has-docs }},
      has-externals: ${{ steps.metadata.outputs.has-externals }},
      has-integration-node: ${{ steps.metadata.outputs.has-integration-node }},
      has-integration-externals:
        ${{ steps.metadata.outputs.has-integration-externals }},
      has-integration-client:
        ${{ steps.metadata.outputs.has-integration-client }},
      has-integration-webpack:
        ${{ steps.metadata.outputs.has-integration-webpack }},
      debug-string: ${{ steps.metadata.outputs.debug-string }},
      committer-name: ${{ steps.metadata.outputs.committer-name }},
      committer-email: ${{ steps.metadata.outputs.committer-email }}

    steps:
      - name: Download metadata artifact
        if: github.event.workflow_run.conclusion == 'success'
        uses: actions/download-artifact@v2
        with:
          name: metadata-${{ runner.os }}-${{ github.sha }}
          path: /tmp

      - name: Import metadata from artifact
        id: metadata
        if: github.event.workflow_run.conclusion == 'success'
        run: |
          node -e "$(cat <<'EOF'
            const readFile = require('fs').readFileSync;
            Object.keys(JSON.parse(readFile('/tmp/meta.json'))).forEach((key, value) => {
              console.log(`imported metadata: name=${key} value=${value}`)
              console.log(`::set-output name=${key}::${value}`)
            });
          EOF
          )"

  upload-coverage:
    name: '[CD] upload-coverage'
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs:
      - metadata
    if: |
      needs.metadata.outputs.should-skip != 'true'
      && needs.metadata.outputs.can-upload-coverage == 'true'
    env:
      DEBUG: ${{ needs.metadata.outputs.debug-string }}

    steps:
      - name: Checkout
        uses: actions/checkout@v2
        with:
          fetch-depth: 0 # ? Codecov action needs access to history
          ref: ${{ needs.metadata.outputs.commit-sha }}
          token: ${{ secrets.GH_TOKEN }}

      - name: Strip repository bare
        run: |
          rm -rf {,.!(git)}

      - name: Download build artifact
        uses: actions/download-artifact@v2
        with:
          name: build-${{ runner.os }}-${{ github.sha }}
          path: ./

      - name: Attempt to upload coverage data to codecov
        uses: codecov/codecov-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }} # not required for public repos
          fail_ci_if_error: false

      - name: Issue any codecov-related warnings
        run: echo '::warning::no code coverage data uploaded for this run'

  release:
    name: '[CD] release'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs:
      - metadata
    if: needs.metadata.outputs.should-skip != 'true'
    env:
      DEBUG: ${{ needs.metadata.outputs.debug-string }}

    steps:
      - name: Checkout
        uses: actions/checkout@v2
        with:
          fetch-depth: 0
          ref: ${{ needs.metadata.outputs.commit-sha }}
          token: ${{ secrets.GH_TOKEN }}

      - name: Strip repository bare
        run: |
          rm -rf {,.!(git)}

      - name: Download build artifact
        uses: actions/download-artifact@v2
        with:
          name: build-${{ runner.os }}-${{ github.sha }}
          path: ./

      - name: Use node ${{ needs.metadata.outputs.node-version }} (for npx only)
        uses: actions/setup-node@v2.1.5
        with:
          node-version: ${{ needs.metadata.outputs.node-version }}

      - name: Import gpg key
        id: gpg
        uses: crazy-max/ghaction-import-gpg@v3
        with:
          gpg-private-key: ${{ secrets.GPG_PRIVATE_KEY }}
          passphrase: ${{ secrets.GPG_PASSPHRASE }}
          git-user-signingkey: true
          git-commit-gpgsign: true
          git-tag-gpgsign: true
          git-committer-name: ${{ needs.metadata.outputs.committer-name }}
          git-committer-email: ${{ needs.metadata.outputs.committer-email }}

      - name: Perform semantic release
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
          NPM_TOKEN: ${{ secrets.NPM_TOKEN }}
          SHOULD_UPDATE_CHANGELOG:
            ${{ needs.metadata.outputs.current-branch == 'main' }}
          SHOULD_DEPLOY: ${{ needs.metadata.outputs.has-deploy == 'true' }}
          GIT_AUTHOR_NAME: ${{ needs.metadata.outputs.committer-name }}
          GIT_AUTHOR_EMAIL: ${{ needs.metadata.outputs.committer-email }}
          GIT_COMMITTER_NAME: ${{ needs.metadata.outputs.committer-name }}
          GIT_COMMITTER_EMAIL: ${{ needs.metadata.outputs.committer-email }}
        run: |
          npx -p debug \
              -p escape-string-regexp \
              -p semver \
              -p execa \
              -p conventional-changelog-angular \
              -p @semantic-release/changelog \
              -p @semantic-release/exec \
              -p @semantic-release/git \
              -p semantic-release \
          semantic-release

  # ? This job always runs except:
  # ? 1. If CI and/or CD are skipped globally or pipeline otherwise failed
  # ? 2. If the "release" job WAS NOT skipped
  # ? 3. If we cannot automerge (bad perms, not a PR, PR is a draft, etc)
  auto-merge:
    name: '[CD] auto-merge'
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs:
      - metadata
      - release
    if: |
      always()
      && needs.metadata.outputs.should-skip != 'true'
      && needs.release.result == 'skipped'
      && needs.metadata.outputs.can-automerge == 'true'
    env:
      DEBUG: ${{ needs.metadata.outputs.debug-string }}

    steps:
      - name: 'Merge pull request'
        uses: actions/github-script@v3
        with:
          github-token: ${{ secrets.GH_TOKEN }}
          script: |
            const MAX_TRIES = 3;
            const MINIMUM_SECONDS = 10;
            const JITTER_SECONDS = 10;

            let success = false;
            let errors = [];
            let jitter = 0;

            const pullRequest = {
              number: ${{ needs.metadata.outputs.pr-number }}
              head: {
                sha: '${{ needs.metadata.outputs.commit-sha }}'
              }
            };

            const repository = context.repo;
            const debugging = !!process.env.DEBUG;
            const canRetryMerge =
              '${{ needs.metadata.outputs.can-retry-automerge }}' == 'true';

            const delay = async (ms) => new Promise((resolve) => setTimeout(resolve, ms));
            const withErrorHandling = (promise, failData = {}) => {
              return promise.catch((e) =>
                Promise.resolve({
                  status: e.status || 0,
                  data: { message: e.message, ...failData }
                })
              );
            };

            if (debugging) {
              console.log('MAX_TRIES:', MAX_TRIES);
              console.log('MINIMUM_SECONDS:', MINIMUM_SECONDS);
              console.log('JITTER_SECONDS:', JITTER_SECONDS);
              console.log('repository:', repository);
              console.log(
                'canRetryMerge:',
                canRetryMerge,
                ' ("${{ needs.metadata.outputs.can-retry-automerge }}")'
              );
              console.log('pullRequest.number:', pullRequest.number);
              console.log(`head_ref (sha): ${pullRequest.head.sha}`);
            }

            for (let tries = 0; !success && tries < MAX_TRIES; ++tries) {
              const failSymbol = Symbol('fail');

              try {
                const latestPullRequest = await withErrorHandling(
                  github.pulls.get(
                    {
                      owner: repository.owner,
                      repo: repository.repo,
                      pull_number: pullRequest.number
                    },
                    { failed: failSymbol }
                  )
                );

                if (debugging) {
                  console.log('latestPullRequest->status:', latestPullRequest.status);
                  console.log(
                    'latestPullRequest->message:',
                    latestPullRequest.data.message
                  );
                  console.log('latestPullRequest->failed:', latestPullRequest.data.failed);
                  console.log('latestPullRequest->state:', latestPullRequest.data.state);
                  console.log('latestPullRequest->merged:', latestPullRequest.data.merged);
                  console.log('latestPullRequest->draft:', latestPullRequest.data.draft);
                }

                if (latestPullRequest.status == 404) {
                  core.warning(
                    `Auto-merge skipped: PR #${pullRequest.number} no longer exists`
                  );
                  return;
                } else if (latestPullRequest.data.failed == failSymbol) {
                  throw new Error(
                    latestPullRequest.data.message ||
                      `failed to get PR #${pullRequest.number}: status code ${status}`
                  );
                } else if (latestPullRequest.data.merged) {
                  core.info(
                    `Auto-merge skipped: PR #${pullRequest.number} has already been merged`
                  );
                  return;
                } else if (latestPullRequest.data.draft) {
                  core.warning(
                    `Auto-merge skipped: PR #${pullRequest.number} was marked as a draft`
                  );
                  return;
                } else if (
                  latestPullRequest.status < 400 &&
                  latestPullRequest.data.state != 'open'
                ) {
                  core.warning(
                    `Auto-merge skipped: PR #${pullRequest.number} is no longer open`
                  );
                  return;
                } // ? Mergeability check is the attempt to merge itself (below)

                const {
                  status,
                  data: { merged, message }
                } = await withErrorHandling(
                  github.pulls.merge({
                    owner: repository.owner,
                    repo: repository.repo,
                    pull_number: pullRequest.number,
                    sha: pullRequest.head.sha,
                    merge_method: 'merge'
                  }),
                  { merged: false }
                );

                if (debugging) {
                  console.log('mergeAttempt->status:', status);
                  console.log('mergeAttempt->message:', message);
                  console.log('mergeAttempt->merged:', merged);
                }

                const defaultError =
                  message ||
                  `failed to merge PR #${pullRequest.number}: status code ${status}`;

                if ([403, 404, 422].includes(status)) {
                  core.setFailed(`Auto-merge failed: ${message}`);
                  return;
                } else if (status == 409) {
                  core.info(
                    `Auto-merge skipped: current HEAD is out of sync with PR #${pullRequest.number}`
                  );
                } else if (status >= 400 && status < 500 && !canRetryMerge) {
                  core.setFailed(`Auto-merge failed: ${defaultError}`);
                  return;
                } else if (!merged) {
                  throw new Error(defaultError);
                }

                success = true;
              } catch (e) {
                console.error(
                  'Auto-merge failed:',
                  e.message || e || 'an unknown error occurred'
                );

                if (tries + 1 < MAX_TRIES) {
                  const nextRetryIn = 2 ** tries * MINIMUM_SECONDS * 1000 + jitter;
                  jitter += Math.random() * JITTER_SECONDS * 1000;
                  core.warning(
                    `Auto-merge attempt ${
                      tries + 1
                    }/${MAX_TRIES} failed, next try in ${Math.round(
                      nextRetryIn / 1000
                    )} seconds`
                  );

                  await delay(nextRetryIn);
                }
              }
            }

            if (!success) core.setFailed(`Auto-merge failed after ${MAX_TRIES} attempts`);
